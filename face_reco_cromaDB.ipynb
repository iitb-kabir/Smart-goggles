{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0443fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93874f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identities found: 49\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "base_path =r\"C:\\Users\\nasir\\OneDrive\\Desktop\\facedata_croped\"\n",
    "all_identities = os.listdir(base_path)\n",
    "print(f\"Identities found: {len(all_identities)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf49a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detector\n",
    "mtcnn = MTCNN(image_size=160, margin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b0c31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract face\n",
    "def extract_face(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    face = mtcnn(img)\n",
    "    if face is not None:\n",
    "        return face\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4204fce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total faces loaded: 1148\n"
     ]
    }
   ],
   "source": [
    "# Load faces\n",
    "data = []\n",
    "labels = []\n",
    "for label, identity in enumerate(all_identities):\n",
    "    identity_path = os.path.join(base_path, identity)\n",
    "    images = os.listdir(identity_path)\n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(identity_path, img_name)\n",
    "        face = extract_face(img_path)\n",
    "        if face is not None:\n",
    "            data.append(face)\n",
    "            labels.append(label)\n",
    "print(f\"Total faces loaded: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "164ce617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack data\n",
    "faces = torch.stack(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f704346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FaceNet model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "facenet = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43844b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for face in faces:\n",
    "        face = face.unsqueeze(0).to(device)\n",
    "        embedding = facenet(face)\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "embeddings = np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "import chromadb\n",
    "# Define a path for persistent storage for your ChromaDB\n",
    "# Make sure this directory exists or can be created by the script.\n",
    "db_path = r\"C:\\Users\\nasir\\OneDrive\\Desktop\\my_chroma_db\"\n",
    "client = chromadb.PersistentClient(path=db_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dff55168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings stored in ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "# Add embeddings to ChromaDB\n",
    "for idx, (embedding, label) in enumerate(zip(embeddings_norm, labels_enc)):\n",
    "    collection.add(\n",
    "        ids=[str(idx)],\n",
    "        embeddings=[embedding.tolist()],\n",
    "        metadatas=[{\"label\": str(label)}],\n",
    "        documents=[all_identities[label]]\n",
    "    )\n",
    "print(\"Embeddings stored in ChromaDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b749b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Identity: Elizabeth Olsen, Confidence: 78.46%\n"
     ]
    }
   ],
   "source": [
    "# Predict function using ChromaDB\n",
    "def predict_identity_chroma(image_path, facenet, mtcnn, in_encoder, collection, device, all_identities, threshold=0.6):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    face = mtcnn(img)\n",
    "    if face is not None:\n",
    "        face = face.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            embedding = facenet(face).cpu().numpy()\n",
    "        embedding = in_encoder.transform(embedding)\n",
    "\n",
    "        result = collection.query(\n",
    "            query_embeddings=embedding.tolist(),\n",
    "            n_results=1\n",
    "        )\n",
    "\n",
    "        if result and result['distances'][0][0] < threshold:\n",
    "            label = result['metadatas'][0][0]['label']\n",
    "            name = result['documents'][0][0]\n",
    "            similarity = 1 - result['distances'][0][0]\n",
    "            return name, similarity * 100\n",
    "        else:\n",
    "            return None, None\n",
    "    else:\n",
    "        return None, None\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\nasir\\OneDrive\\Pictures\\Screenshots\\Screenshot 2025-07-04 204102.png\" # Change this to your test image\n",
    "identity, confidence = predict_identity_chroma(\n",
    "    image_path, facenet, mtcnn, in_encoder, collection, device, all_identities\n",
    ")\n",
    "\n",
    "if identity is not None:\n",
    "    print(f'Predicted Identity: {identity}, Confidence: {confidence:.2f}%')\n",
    "else:\n",
    "    print(\"No face detected or identity not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "869ca8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all_identities_CDB.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(all_identities, 'all_identities_CDB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a97017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
